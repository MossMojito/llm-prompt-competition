# ğŸš€ QUICK START - Read This First!

**Welcome to the LLM Prompt Engineering Competition!**

You've downloaded a complete, production-ready project for teaching prompt engineering through hands-on competition.

---

## ğŸ“¦ What's Included

This project contains **everything** you need:

âœ… **Complete Documentation** - Setup guides, competition rules, learning materials
âœ… **Working Code** - Data loaders, evaluation system, example prompts  
âœ… **Sample Data** - Ready-to-use IMDb sentiment analysis dataset
âœ… **Example Submissions** - Learn from real examples
âœ… **Databricks Integration** - Notebooks and configuration for collaborative learning

---

## ğŸ¯ For Instructors

### Getting Started (15 minutes)

1. **Upload to GitHub**
   ```bash
   cd llm-prompt-engineering-competition
   git init
   git add .
   git commit -m "Initial commit"
   git remote add origin <your-repo-url>
   git push -u origin main
   ```

2. **Set Up Databricks**
   - Import repository to Databricks workspace
   - Create shared cluster (see `docs/SETUP.md`)
   - Install dependencies from `requirements.txt`

3. **Prepare Data**
   ```python
   # Run in Databricks notebook
   from data.load_data import load_imdb_dataset, create_sample_dataset
   
   dataset = load_imdb_dataset()
   create_sample_dataset(dataset)
   ```

4. **Share with Students**
   - Give them repository access
   - Direct them to `docs/SETUP.md`
   - Point them to `docs/COMPETITION_RULES.md`

### Customization

**Change the model**: Edit `configs/model_config.yaml`
**Adjust timeline**: Update `docs/COMPETITION_RULES.md`
**Modify scoring**: Edit `src/evaluation/metrics.py`
**Add datasets**: Extend `data/load_data.py`

---

## ğŸ‘¨â€ğŸ“ For Students

### Your Learning Path

1. **Week 1: Learn**
   - Read `docs/SETUP.md` - Get environment ready
   - Read `docs/PROMPT_ENGINEERING_GUIDE.md` - Learn techniques
   - Study `src/prompts/example_prompts.py` - See examples
   - Explore `src/prompts/student_prompts/alice_example.py`

2. **Week 2: Build**
   - Copy `src/prompts/student_prompts/template.py`
   - Implement your prompt strategy
   - Test with sample data
   - Submit via Pull Request

3. **Week 3: Compete**
   - Automated evaluation runs
   - Leaderboard announced
   - Learn from winners

4. **Week 4: Share**
   - Winners present strategies
   - Everyone improves
   - Celebrate learning!

### Quick Test

```python
# Test your prompt in Databricks
from src.evaluation.evaluator import quick_test

results = quick_test('your_name')
# Shows accuracy, F1 score, confusion matrix
```

---

## ğŸ“ Project Structure

```
llm-prompt-engineering-competition/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    â† Project overview, start here!
â”œâ”€â”€ ğŸ“„ requirements.txt             â† Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                   â† Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“ data/                        â† Dataset management
â”‚   â”œâ”€â”€ load_data.py                â† Load IMDb dataset
â”‚   â”œâ”€â”€ sample_data/                â† Small test datasets
â”‚   â””â”€â”€ README.md                   â† Data documentation
â”‚
â”œâ”€â”€ ğŸ“ src/                         â† Source code
â”‚   â”œâ”€â”€ prompts/                    
â”‚   â”‚   â”œâ”€â”€ example_prompts.py      â† Learn from these!
â”‚   â”‚   â””â”€â”€ student_prompts/        
â”‚   â”‚       â”œâ”€â”€ template.py         â† Copy this to start
â”‚   â”‚       â”œâ”€â”€ alice_example.py    â† Example submission
â”‚   â”‚       â””â”€â”€ README.md           â† How to submit
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/                 
â”‚       â”œâ”€â”€ metrics.py              â† Scoring functions
â”‚       â””â”€â”€ evaluator.py            â† Main evaluation engine
â”‚
â”œâ”€â”€ ğŸ“ docs/                        â† Full documentation
â”‚   â”œâ”€â”€ SETUP.md                    â† Databricks setup guide
â”‚   â”œâ”€â”€ COMPETITION_RULES.md        â† Rules and timeline
â”‚   â””â”€â”€ PROMPT_ENGINEERING_GUIDE.md â† Learn prompt engineering
â”‚
â”œâ”€â”€ ğŸ“ configs/                     â† Configuration files
â”‚   â””â”€â”€ model_config.yaml           â† Model and eval settings
â”‚
â””â”€â”€ ğŸ“ results/                     â† Competition results
    â””â”€â”€ leaderboard.md              â† Current rankings
```

---

## ğŸ“ Key Concepts You'll Learn

1. **How LLMs Work** - Decoder-only models, text generation
2. **Prompt Engineering** - Zero-shot, few-shot, chain-of-thought
3. **Evaluation Metrics** - Accuracy, F1, precision, recall
4. **Real ML Workflows** - Data â†’ Model â†’ Evaluation â†’ Iteration

---

## ğŸ”¥ Ready to Start?

### Option 1: Read Everything First (Recommended)
1. `README.md` â† You are here
2. `docs/SETUP.md` â† Set up environment
3. `docs/COMPETITION_RULES.md` â† Understand the game
4. `docs/PROMPT_ENGINEERING_GUIDE.md` â† Master the techniques
5. Start building!

### Option 2: Jump Right In (For Brave Souls)
1. Copy `template.py` to `your_name.py`
2. Write your prompt
3. Run `quick_test('your_name')`
4. Iterate until good
5. Submit!

---

## ğŸ“š Additional Resources

**Inside This Project:**
- `src/prompts/example_prompts.py` - Good vs bad prompts
- `src/prompts/student_prompts/alice_example.py` - Full example
- All documentation in `docs/`

**External Resources:**
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [HuggingFace Docs](https://huggingface.co/docs/transformers)
- [Databricks Learning](https://databricks.com/learn)

---

## ğŸ’¡ Pro Tips

1. **Start Simple** - Don't overcomplicate your first prompt
2. **Test Often** - Use sample data for quick iteration
3. **Learn from Examples** - Study `example_prompts.py`
4. **Ask Questions** - Use GitHub issues or course chat
5. **Have Fun!** - This is about learning, not just winning

---

## ğŸ†˜ Need Help?

**Technical Issues**
- Check `docs/SETUP.md` troubleshooting section
- Open GitHub issue with error details

**Prompt Engineering Questions**
- Read `docs/PROMPT_ENGINEERING_GUIDE.md`
- Study example prompts
- Ask instructor in workspace chat

**Competition Rules**
- Read `docs/COMPETITION_RULES.md`
- Check FAQs section
- Ask instructor for clarification

---

## ğŸ† Competition Goals

**Learning Objectives:**
- âœ… Understand LLMs and text generation
- âœ… Master prompt engineering techniques
- âœ… Practice ML evaluation and iteration
- âœ… Build real-world ML projects

**Not Just About Winning:**
- ğŸ¯ Experiment and learn
- ğŸ¯ Help each other grow
- ğŸ¯ Share knowledge
- ğŸ¯ Have fun with AI!

---

## ğŸ“ Support

- **GitHub Issues**: Technical problems
- **Course Chat**: Questions and discussion
- **Instructor**: Direct help and guidance

---

## âœ… Pre-Flight Checklist

Before you start competing:

- [ ] Read this file (you're doing it!)
- [ ] Understand project structure
- [ ] Review `docs/SETUP.md`
- [ ] Read `docs/COMPETITION_RULES.md`
- [ ] Study `docs/PROMPT_ENGINEERING_GUIDE.md`
- [ ] Look at example prompts
- [ ] Set up Databricks environment
- [ ] Test that you can run code
- [ ] Feel excited! ğŸš€

---

**You're all set! Welcome to the competition!**

**May the best prompt win!** ğŸ†

*Remember: The goal is to learn and have fun. Experiment boldly!*

---

## ğŸ“ What to Do Next

1. **Read** `README.md` in the main folder
2. **Follow** `docs/SETUP.md` to set up Databricks
3. **Study** `docs/PROMPT_ENGINEERING_GUIDE.md`
4. **Build** your first prompt
5. **Compete** and learn!

**Good luck!** ğŸ“
